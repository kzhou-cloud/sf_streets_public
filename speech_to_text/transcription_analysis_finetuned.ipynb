{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Import all required libraries\n",
    "# ============================================================================\n",
    "\n",
    "# Add parent directory to path to import utils\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    normalize_text,\n",
    "    categorize_language,\n",
    "    group_language_by_family,\n",
    "    read_transcription_data,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Bootstrap Resampling Utilities\n",
    "# ============================================================================\n",
    "def bootstrap_mean(data, n_bootstrap=1000, confidence_level=0.95, random_state=42):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence intervals for the mean.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Binary data (0s and 1s for accuracy)\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples\n",
    "    confidence_level : float\n",
    "        Confidence level (e.g., 0.95 for 95% CI)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    mean : float\n",
    "        Point estimate (mean)\n",
    "    ci_lower : float\n",
    "        Lower bound of confidence interval\n",
    "    ci_upper : float\n",
    "        Upper bound of confidence interval\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n = len(data)\n",
    "    \n",
    "    if n == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Generate bootstrap samples\n",
    "    bootstrap_means = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrap_means.append(np.mean(sample))\n",
    "    \n",
    "    # Compute percentiles for CI\n",
    "    alpha = 1 - confidence_level\n",
    "    ci_lower = np.percentile(bootstrap_means, 100 * alpha / 2)\n",
    "    ci_upper = np.percentile(bootstrap_means, 100 * (1 - alpha / 2))\n",
    "    mean = np.mean(data)\n",
    "    \n",
    "    return mean, ci_lower, ci_upper\n",
    "\n",
    "# ============================================================================\n",
    "# Configure visualization settings\n",
    "# ============================================================================\n",
    "# Use DejaVu Sans which is commonly available on Linux systems\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "\n",
    "# Set seaborn style for cleaner plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.4)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION: All four model sizes analyzed simultaneously\n",
    "# ============================================================================\n",
    "\n",
    "# Each entry maps: baseline model name -> finetuned model name\n",
    "MODEL_PAIRS = {\n",
    "    \"tiny\": \"whisper_tiny_im_on_all_17863_20260130_131358\",\n",
    "    \"base\": \"whisper_base_im_on_all_17862_20260130_131358\",\n",
    "    \"medium\": \"whisper_medium_im_on_all_17864_20260130_131403\",\n",
    "    \"small\": \"whisper_small_im_on_all_18126_20260206_163258\",\n",
    "    \"large\": \"whisper_large_im_on_all_17861_20260130_131353\",\n",
    "}\n",
    "\n",
    "# Per-language finetuned models: model name -> language code\n",
    "LANG_MODEL_TO_CODE = {\n",
    "    \"whisper_base_im_on_ar_18089_20260206_131541\":    \"ar\",\n",
    "    \"whisper_base_im_on_cs_18089_20260206_131543\":    \"cs\",\n",
    "    \"whisper_base_im_on_de_18089_20260206_131542\":    \"de\",\n",
    "    \"whisper_base_im_on_es_18089_20260206_131543\":    \"es\",\n",
    "    \"whisper_base_im_on_fr_18089_20260206_131652\":    \"fr\",\n",
    "    \"whisper_base_im_on_hi_18089_20260206_131641\":    \"hi\",\n",
    "    \"whisper_base_im_on_hu_18089_20260206_131656\":    \"hu\",\n",
    "    \"whisper_base_im_on_it_18108_20260206_135235\":    \"it\",\n",
    "    \"whisper_base_im_on_ja_18118_20260206_142832\":    \"ja\",\n",
    "    \"whisper_base_im_on_ko_18089_20260206_132907\":    \"ko\",\n",
    "    \"whisper_base_im_on_nl_18089_20260206_132915\":    \"nl\",\n",
    "    \"whisper_base_im_on_pl_18089_20260206_132927\":    \"pl\",\n",
    "    \"whisper_base_im_on_pt_18089_20260206_132927\":    \"pt\",\n",
    "    \"whisper_base_im_on_ru_18089_20260206_133021\":    \"ru\",\n",
    "    \"whisper_base_im_on_tr_18089_20260206_133039\":    \"tr\",\n",
    "    \"whisper_base_im_on_zh-cn_18108_20260206_135234\": \"zh-cn\",\n",
    "}\n",
    "\n",
    "# All per-language models map to \"base\" size\n",
    "LANG_MODEL_PAIRS = {model: \"base\" for model in LANG_MODEL_TO_CODE}\n",
    "\n",
    "# Add a 'model_size' column to tag each row with its size (tiny/base/medium/large)\n",
    "def get_model_size(model_name):\n",
    "    \"\"\"Map a model name (baseline or finetuned) to its size label.\"\"\"\n",
    "    if model_name in MODEL_PAIRS:\n",
    "        return model_name\n",
    "    for baseline, finetuned in MODEL_PAIRS.items():\n",
    "        if model_name == finetuned:\n",
    "            return baseline\n",
    "    if model_name in LANG_MODEL_PAIRS:\n",
    "        return LANG_MODEL_PAIRS[model_name]\n",
    "    return 'unknown'\n",
    "\n",
    "# Convenience lists\n",
    "BASELINE_MODELS = list(MODEL_PAIRS.keys())\n",
    "FINETUNED_MODELS = list(MODEL_PAIRS.values())\n",
    "ALL_MODELS = BASELINE_MODELS + FINETUNED_MODELS\n",
    "\n",
    "# Whether to compare with baseline models or only analyze finetuned models\n",
    "COMPARE_WITH_OTHER_MODELS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model pairs ({len(MODEL_PAIRS)}):\")\n",
    "for baseline, finetuned in MODEL_PAIRS.items():\n",
    "    print(f\"  {baseline} -> {finetuned}\")\n",
    "print(f\"\\nComparing with baseline models: {COMPARE_WITH_OTHER_MODELS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31870028",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = read_transcription_data(\"all\")\n",
    "all_data = all_data[all_data['prompt']=='No prompt']\n",
    "street_origin = pd.read_csv(\"../street_names.tsv\")\n",
    "street_origin['name'] = street_origin['name'].str.lower()\n",
    "\n",
    "all_data = all_data.set_index(\"answer\").join(street_origin.set_index(\"name\"), how='left').reset_index()\n",
    "\n",
    "all_data.columns = ['answer', 'participant_id', 'index', 'model', 'prompt', 'original_text',\n",
    "       'transcription', 'transcription_og', 'Status', 'Primary language',\n",
    "       'Age', 'Sex', 'Language', 'english_only', 'multilingual', 'not_english',\n",
    "       'levenshtein_distance', 'is_correct', 'age_decade', 'origin']\n",
    "all_data['correct'] = all_data['transcription'] == all_data['answer']\n",
    "all_data['language_family'] = all_data['Primary language'].apply(group_language_by_family)\n",
    "\n",
    "\n",
    "\n",
    "all_data['model_size'] = all_data['model'].apply(get_model_size)\n",
    "\n",
    "# Add a 'model_type' column: 'baseline' or 'finetuned'\n",
    "all_finetuned = list(MODEL_PAIRS.values()) + list(LANG_MODEL_PAIRS.keys())\n",
    "all_data['model_type'] = all_data['model'].apply(\n",
    "    lambda m: 'finetuned' if m in all_finetuned else 'baseline'\n",
    ")\n",
    "\n",
    "# --- data: MODEL_PAIRS models only (baselines + their finetuned counterparts) ---\n",
    "data = all_data[all_data['model'].isin(ALL_MODELS)].copy()\n",
    "print(f\"data: Filtered to {len(ALL_MODELS)} models ({len(data)} rows)\")\n",
    "print(f\"  Models: {ALL_MODELS}\")\n",
    "\n",
    "print(f\"\\nModels loaded per size:\")\n",
    "for size in BASELINE_MODELS:\n",
    "    subset = data[data['model_size'] == size]\n",
    "    n_baseline = len(subset[subset['model_type'] == 'baseline'])\n",
    "    n_finetuned = len(subset[subset['model_type'] == 'finetuned'])\n",
    "    print(f\"  {size}: {n_baseline} baseline samples, {n_finetuned} finetuned samples\")\n",
    "\n",
    "# --- data_lang: LANG_MODEL_PAIRS models + base baseline ---\n",
    "lang_models_to_keep = ['base'] + list(LANG_MODEL_PAIRS.keys())\n",
    "data_lang = all_data[all_data['model'].isin(lang_models_to_keep)].copy()\n",
    "\n",
    "# Add lang_code column (NaN for baseline, language code for per-language finetuned)\n",
    "data_lang['lang_code'] = data_lang['model'].map(LANG_MODEL_TO_CODE)\n",
    "\n",
    "print(f\"\\ndata_lang: {len(lang_models_to_keep)} models ({len(data_lang)} rows)\")\n",
    "print(f\"  Languages: {sorted(data_lang['lang_code'].dropna().unique())}\")\n",
    "print(f\"  Baseline (base) samples: {len(data_lang[data_lang['model'] == 'base'])}\")\n",
    "print(f\"  Per-language finetuned samples: {len(data_lang[data_lang['model'] != 'base'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d72cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy between all models\n",
    "print(\"=\" * 60)\n",
    "print(\"OVERALL ACCURACY COMPARISON (All Model Sizes)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall accuracy table\n",
    "print(\"\\nOverall Accuracy by Model:\")\n",
    "accuracy_by_model = data.groupby('model')['is_correct'].agg(['mean', 'count', 'sum'])\n",
    "accuracy_by_model.columns = ['Accuracy', 'Total Samples', 'Correct']\n",
    "accuracy_by_model = accuracy_by_model.sort_values('Accuracy', ascending=False)\n",
    "display(accuracy_by_model.round(3))\n",
    "\n",
    "# Summary table by model size (baseline vs finetuned)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACCURACY BY MODEL SIZE (Baseline vs Finetuned)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_rows = []\n",
    "for size in BASELINE_MODELS:\n",
    "    baseline_data = data[(data['model_size'] == size) & (data['model_type'] == 'baseline')]\n",
    "    finetuned_data = data[(data['model_size'] == size) & (data['model_type'] == 'finetuned')]\n",
    "    \n",
    "    b_acc = baseline_data['is_correct'].mean() if len(baseline_data) > 0 else float('nan')\n",
    "    f_acc = finetuned_data['is_correct'].mean() if len(finetuned_data) > 0 else float('nan')\n",
    "    delta = f_acc - b_acc if not (np.isnan(b_acc) or np.isnan(f_acc)) else float('nan')\n",
    "    \n",
    "    summary_rows.append({\n",
    "        'Model Size': size,\n",
    "        'Baseline Acc': round(b_acc, 3),\n",
    "        'Baseline N': len(baseline_data),\n",
    "        'Finetuned Acc': round(f_acc, 3),\n",
    "        'Finetuned N': len(finetuned_data),\n",
    "        'Delta': round(delta, 3),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(data[data['model'].str.contains(\"im_on\")].groupby(\"language_group\").mean(numeric_only=True)[['is_correct']])\n",
    "# display(data[~data['model'].str.contains(\"im_on\")].groupby(\"language_group\").mean(numeric_only=True)[['is_correct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617865da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.823103 - 0.648621) / 0.648621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.779310 - 0.455172)/0.455172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Figure 1: Accuracy by Language Group with Bootstrap Confidence Intervals\n",
    "# ============================================================================\n",
    "\n",
    "# Create language group column based on english_only, multilingual, not_english\n",
    "def get_language_group(row):\n",
    "    if row['english_only']:\n",
    "        return 'English Only'\n",
    "    elif row['multilingual']:\n",
    "        return 'Multilingual'\n",
    "    elif row['not_english']:\n",
    "        return 'Non-English'\n",
    "    return 'Unknown'\n",
    "\n",
    "data['language_group'] = data.apply(get_language_group, axis=1)\n",
    "\n",
    "\n",
    "def plot_accuracy_by_language_group(data, model_sizes, model_types, title, save_path,\n",
    "                                    order_by_type='finetuned', colors=None):\n",
    "    \"\"\"\n",
    "    Plot accuracy by language group with bootstrap confidence intervals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        Must contain columns: language_group, model_size, model_type, is_correct\n",
    "    model_sizes : list[str]\n",
    "        Model sizes to create subplots for (e.g. ['tiny', 'base', ...])\n",
    "    model_types : list[str]\n",
    "        Model types to compare (e.g. ['baseline'] or ['baseline', 'finetuned'])\n",
    "    title : str\n",
    "        Figure suptitle\n",
    "    save_path : str\n",
    "        Path to save the figure\n",
    "    order_by_type : str\n",
    "        Which model_type to use for ordering language groups (descending accuracy).\n",
    "        Falls back to first available type if not found.\n",
    "    colors : dict, optional\n",
    "        Mapping of model_type -> color. Defaults provided for baseline/finetuned.\n",
    "    \"\"\"\n",
    "    if colors is None:\n",
    "        colors = {'baseline': '#3498db', 'finetuned': '#e74c3c'}\n",
    "\n",
    "    lang_groups = sorted(data['language_group'].unique())\n",
    "\n",
    "    # Compute bootstrap CIs\n",
    "    results = []\n",
    "    for lang_group in lang_groups:\n",
    "        for size in model_sizes:\n",
    "            for model_type in model_types:\n",
    "                subset = data[(data['language_group'] == lang_group) &\n",
    "                              (data['model_size'] == size) &\n",
    "                              (data['model_type'] == model_type)]\n",
    "                if len(subset) > 0:\n",
    "                    accuracy_data = subset['is_correct'].values\n",
    "                    mean, ci_lower, ci_upper = bootstrap_mean(accuracy_data, n_bootstrap=1000)\n",
    "                    results.append({\n",
    "                        'language_group': lang_group,\n",
    "                        'model_size': size,\n",
    "                        'model_type': model_type,\n",
    "                        'accuracy': mean,\n",
    "                        'ci_lower': ci_lower,\n",
    "                        'ci_upper': ci_upper,\n",
    "                        'n_samples': len(subset)\n",
    "                    })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Determine language group ordering\n",
    "    order_candidates = [order_by_type] + [t for t in model_types if t != order_by_type]\n",
    "    lang_group_order = lang_groups\n",
    "    for otype in order_candidates:\n",
    "        order_data = results_df[(results_df['model_size'] == model_sizes[0]) &\n",
    "                                (results_df['model_type'] == otype)]\n",
    "        if len(order_data) > 0:\n",
    "            lang_group_order = (order_data.set_index('language_group')['accuracy']\n",
    "                                .sort_values(ascending=False).index.tolist())\n",
    "            break\n",
    "\n",
    "    # Create subplots: one per model size\n",
    "    n_types = len(model_types)\n",
    "    n_sizes = len(model_sizes)\n",
    "    fig, axes = plt.subplots(1, n_sizes, figsize=(8 * n_sizes, 9), sharey=True)\n",
    "    if n_sizes == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    x = np.arange(len(lang_group_order))\n",
    "    width = 0.35 if n_types > 1 else 0.5\n",
    "\n",
    "    for ax_idx, size in enumerate(model_sizes):\n",
    "        ax = axes[ax_idx]\n",
    "\n",
    "        for i, model_type in enumerate(model_types):\n",
    "            model_data = (results_df[(results_df['model_size'] == size) &\n",
    "                                     (results_df['model_type'] == model_type)]\n",
    "                          .set_index('language_group').reindex(lang_group_order))\n",
    "\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "\n",
    "            accuracies = model_data['accuracy'].values\n",
    "            ci_lowers = model_data['ci_lower'].values\n",
    "            ci_uppers = model_data['ci_upper'].values\n",
    "            errors = np.array([accuracies - ci_lowers, ci_uppers - accuracies])\n",
    "\n",
    "            if n_types == 1:\n",
    "                offset = 0\n",
    "            else:\n",
    "                offset = -width / 2 if i == 0 else width / 2\n",
    "            color = colors.get(model_type, f'C{i}')\n",
    "            label = f'{model_type.capitalize()} ({size})'\n",
    "\n",
    "            bars = ax.bar(x + offset, accuracies, width, label=label,\n",
    "                          color=color, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "\n",
    "            # Error bars (95% CI)\n",
    "            ax.errorbar(x + offset, accuracies, yerr=errors, fmt='none',\n",
    "                        ecolor='black', capsize=4, capthick=1.5, alpha=0.7, linewidth=1.5)\n",
    "\n",
    "            # Value labels on bars\n",
    "            for j, (bar, acc, n_samp) in enumerate(zip(bars, accuracies, model_data['n_samples'].values)):\n",
    "                height = bar.get_height()\n",
    "                ax.annotate(f'{acc:.2f}\\n(n={n_samp})',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 5), textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Styling per subplot\n",
    "        ax.set_xlabel('Language Group', fontsize=18, fontweight='bold')\n",
    "        if ax_idx == 0:\n",
    "            ax.set_ylabel('Accuracy', fontsize=18, fontweight='bold')\n",
    "        ax.set_title(f'whisper-{size}', fontsize=20, fontweight='bold', pad=12)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(lang_group_order, rotation=0, ha='center', fontsize=16)\n",
    "        ax.legend(loc='lower right', fontsize=14, frameon=True, shadow=True)\n",
    "        ax.set_ylim(0, 1.15)\n",
    "        ax.yaxis.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "    fig.suptitle(title, fontsize=22, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# --- Figure 1a: Finetuned vs Baseline ---\n",
    "plot_accuracy_by_language_group(\n",
    "    data, BASELINE_MODELS, ['baseline', 'finetuned'],\n",
    "    title='Accuracy by Language Group: Finetuned vs Baseline (All Model Sizes)\\n(with 95% Bootstrap Confidence Intervals)',\n",
    "    save_path='figures/accuracy_finetuned_vs_baseline_by_language_group.png',\n",
    "    order_by_type='finetuned',\n",
    ")\n",
    "\n",
    "# --- Figure 1b: whisper-base only (baseline vs finetuned) ---\n",
    "plot_accuracy_by_language_group(\n",
    "    data, ['base'], ['baseline', 'finetuned'],\n",
    "    title='Accuracy by Language Group: whisper-base (Baseline vs Finetuned)\\n(with 95% Bootstrap Confidence Intervals)',\n",
    "    save_path='figures/accuracy_base_model_by_language_group.png',\n",
    "    order_by_type='finetuned',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary columns for each individual language\n",
    "# Parse comma-separated languages and create one column per language\n",
    "\n",
    "# Extract all individual languages from Primary language column\n",
    "all_languages = set()\n",
    "for lang_str in data['Primary language'].dropna():\n",
    "    for lang in lang_str.split(','):\n",
    "        all_languages.add(lang.strip())\n",
    "\n",
    "# Create a binary column for each individual language\n",
    "for lang in sorted(all_languages):\n",
    "    col_name = f'lang_{lang.replace(\" \", \"_\")}'\n",
    "    data[col_name] = data['Primary language'].apply(\n",
    "        lambda x: 1 if pd.notna(x) and lang.lower() in x.lower() else 0\n",
    "    )\n",
    "\n",
    "# Create English-only speaker column (monolingual English)\n",
    "data['english_only_speaker'] = data['Primary language'].apply(\n",
    "    lambda x: 1 if pd.notna(x) and x.strip().lower() == 'english' else 0\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "lang_cols = [c for c in data.columns if c.startswith('lang_')]\n",
    "print(f\"Created {len(lang_cols)} language columns: {lang_cols}\")\n",
    "print(f\"English-only speakers: {data['english_only_speaker'].sum() // 2}\")  # Divide by 2 for 2 models\n",
    "\n",
    "# Show sample of participant-level data\n",
    "participant_langs = data.groupby('participant_id')[lang_cols + ['english_only_speaker']].max()\n",
    "print(f\"\\nParticipants x Languages ({participant_langs.shape[0]} participants):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Figure 2: Accuracy by Language with Bootstrap Confidence Intervals\n",
    "# ============================================================================\n",
    "\n",
    "# Languages that had synthetic training data (based on voice cloning)\n",
    "LANGUAGES_WITH_TRAINING_DATA = {\n",
    "    'Arabic', 'Czech', 'German', 'Spanish', 'French', 'Hindi', 'Hungarian', \n",
    "    'Italian', 'Japanese', 'Korean', 'Dutch', 'Polish', 'Portuguese', \n",
    "    'Russian', 'Turkish', 'Chinese'\n",
    "}\n",
    "\n",
    "# Get language columns and clean names\n",
    "lang_cols = [c for c in data.columns if c.startswith('lang_')]\n",
    "lang_names = [c.replace('lang_', '').replace(\"'\", \"\").replace(\"_\", \" \") for c in lang_cols]\n",
    "\n",
    "def has_training_data(lang):\n",
    "    return any(train_lang.lower() in lang.lower() for train_lang in LANGUAGES_WITH_TRAINING_DATA)\n",
    "\n",
    "# Compute accuracy with bootstrap for each language (base model only)\n",
    "results = []\n",
    "for col, lang in zip(lang_cols, lang_names):\n",
    "    for model_type in ['baseline', 'finetuned']:\n",
    "        subset = data[(data[col] == 1) & \n",
    "                     (data['model_size'] == 'base') & \n",
    "                     (data['model_type'] == model_type)]\n",
    "        if len(subset) > 0:\n",
    "            accuracy_data = subset['is_correct'].values\n",
    "            mean, ci_lower, ci_upper = bootstrap_mean(accuracy_data, n_bootstrap=1000)\n",
    "            results.append({\n",
    "                'language': lang,\n",
    "                'model_type': model_type,\n",
    "                'accuracy': mean,\n",
    "                'ci_lower': ci_lower,\n",
    "                'ci_upper': ci_upper,\n",
    "                'n_samples': len(subset),\n",
    "                'has_training': has_training_data(lang)\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by finetuned accuracy: languages WITH training data first (by accuracy desc)\n",
    "ft_results = results_df[results_df['model_type'] == 'finetuned']\n",
    "if len(ft_results) > 0:\n",
    "    finetuned_acc = ft_results.set_index('language')['accuracy']\n",
    "    finetuned_training = ft_results.set_index('language')['has_training']\n",
    "    lang_order = sorted(\n",
    "        finetuned_acc.index, \n",
    "        key=lambda x: (not finetuned_training.get(x, False), -finetuned_acc.get(x, 0))\n",
    "    )\n",
    "else:\n",
    "    lang_order = lang_names\n",
    "\n",
    "# Create single plot for base model\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(lang_order))\n",
    "width = 0.35\n",
    "\n",
    "for i, model_type in enumerate(['baseline', 'finetuned']):\n",
    "    model_data = results_df[results_df['model_type'] == model_type].set_index('language').reindex(lang_order)\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    accuracies = model_data['accuracy'].values\n",
    "    ci_lowers = model_data['ci_lower'].values\n",
    "    ci_uppers = model_data['ci_upper'].values\n",
    "    has_training = model_data['has_training'].values\n",
    "    errors = np.array([accuracies - ci_lowers, ci_uppers - accuracies])\n",
    "    \n",
    "    offset = -width/2 if i == 0 else width/2\n",
    "    \n",
    "    # Color based on training data availability\n",
    "    if i == 0:  # Baseline\n",
    "        colors = ['#3498db' if ht else '#a9cce3' for ht in has_training]\n",
    "    else:  # Finetuned\n",
    "        colors = ['#e74c3c' if ht else '#f5b7b1' for ht in has_training]\n",
    "    \n",
    "    # Plot bars\n",
    "    for j, (acc, err_lower, err_upper, color, n_samples) in enumerate(zip(\n",
    "        accuracies, errors[0], errors[1], colors, model_data['n_samples'].values\n",
    "    )):\n",
    "        if np.isnan(acc):\n",
    "            continue\n",
    "        bar = ax.bar(x[j] + offset, acc, width, color=color, alpha=0.8, \n",
    "                     edgecolor='white', linewidth=1.5)\n",
    "        \n",
    "        # Add error bar\n",
    "        ax.errorbar(x[j] + offset, acc, yerr=[[err_lower], [err_upper]], \n",
    "                   fmt='none', ecolor='black', capsize=3, capthick=1.2, \n",
    "                   alpha=0.7, linewidth=1.2)\n",
    "        \n",
    "        # Add value label\n",
    "        ax.annotate(f'{acc:.2f}', \n",
    "                   xy=(x[j] + offset, acc),\n",
    "                   xytext=(0, 3), textcoords=\"offset points\", \n",
    "                   ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add legend with both colors\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#3498db', alpha=0.8, label='Baseline (w/ training)'),\n",
    "    Patch(facecolor='#a9cce3', alpha=0.8, label='Baseline (no training)'),\n",
    "    Patch(facecolor='#e74c3c', alpha=0.8, label='Finetuned (w/ training)'),\n",
    "    Patch(facecolor='#f5b7b1', alpha=0.8, label='Finetuned (no training)'),\n",
    "]\n",
    "\n",
    "ax.set_xlabel('Language', fontsize=18, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontsize=18, fontweight='bold')\n",
    "ax.set_title('whisper-base: Accuracy by Language (Finetuned vs Baseline)\\n(with 95% Bootstrap Confidence Intervals)',\n",
    "             fontsize=20, fontweight='bold', pad=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(lang_order, rotation=45, ha='right', fontsize=16)\n",
    "ax.legend(handles=legend_elements, loc='lower left', fontsize=14, frameon=True, shadow=True)\n",
    "ax.set_ylim(0, 1.15)\n",
    "ax.yaxis.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/accuracy_finetuned_vs_baseline_by_language.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lang['lang_code'].fillna('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Join each per-language finetuned model with the base baseline on (participant_id, answer)\n",
    "# ============================================================================\n",
    "\n",
    "data_lang['lang_code'] = data_lang['lang_code'].fillna(\"base\")\n",
    "\n",
    "# Separate base baseline rows and per-language finetuned rows\n",
    "base_rows = data_lang[data_lang['model'] == 'base'][['participant_id', 'answer', 'transcription', 'is_correct']].copy()\n",
    "base_rows = base_rows.rename(columns={\n",
    "    'transcription': 'base_transcription',\n",
    "    'is_correct': 'base_is_correct',\n",
    "})\n",
    "\n",
    "lang_rows = data_lang[data_lang['model'] != 'base'].copy()\n",
    "\n",
    "# Join: for each finetuned row, attach the base model's result on the same (participant_id, answer)\n",
    "data_lang_merged = lang_rows.merge(base_rows, on=['participant_id', 'answer'], how='left')\n",
    "\n",
    "# Useful derived columns\n",
    "data_lang_merged['both_correct'] = data_lang_merged['is_correct'] & data_lang_merged['base_is_correct']\n",
    "data_lang_merged['finetuned_improved'] = data_lang_merged['is_correct'] & ~data_lang_merged['base_is_correct']\n",
    "data_lang_merged['finetuned_regressed'] = ~data_lang_merged['is_correct'] & data_lang_merged['base_is_correct']\n",
    "data_lang_merged['overall_improvement'] = data_lang_merged['is_correct'].astype(int) - data_lang_merged['base_is_correct'].astype(int)\n",
    "\n",
    "print(f\"\\nOverall: base accuracy = {data_lang_merged['base_is_correct'].mean():.3f}, \"\n",
    "      f\"finetuned accuracy = {data_lang_merged['is_correct'].mean():.3f}\")\n",
    "print(f\"Improved: {data_lang_merged['finetuned_improved'].sum()}, \"\n",
    "      f\"Regressed: {data_lang_merged['finetuned_regressed'].sum()}\")\n",
    "data_lang_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lang_merged.groupby(['lang_code']).mean(numeric_only=True)[['overall_improvement']].sort_values(by='overall_improvement', ascending=False)\n",
    "\n",
    "#0.289 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Heatmap: finetuned improvement rate by lang_code \u00d7 language_family\n",
    "# ============================================================================\n",
    "\n",
    "# Pivot the grouped means into a 2D matrix\n",
    "heatmap_data = (data_lang_merged\n",
    "    .groupby(['lang_code', 'Primary language'])['overall_improvement']\n",
    "    .mean()\n",
    "    .unstack(fill_value=np.nan))\n",
    "\n",
    "# Add whisper_base_im_on_all (finetuned on all languages) as an extra row\n",
    "base_all_model = MODEL_PAIRS['base']  # whisper_base_im_on_all\n",
    "base_all_rows = all_data[all_data['model'] == base_all_model].copy()\n",
    "base_baseline_rows = all_data[all_data['model'] == 'base'][['participant_id', 'answer', 'is_correct']].copy()\n",
    "base_baseline_rows = base_baseline_rows.rename(columns={'is_correct': 'base_is_correct'})\n",
    "base_all_merged = base_all_rows.merge(base_baseline_rows, on=['participant_id', 'answer'], how='left')\n",
    "base_all_merged['overall_improvement'] = base_all_merged['is_correct'].astype(int) - base_all_merged['base_is_correct'].astype(int)\n",
    "base_all_improvement = base_all_merged.groupby('Primary language')['overall_improvement'].mean()\n",
    "heatmap_data.loc['all'] = base_all_improvement\n",
    "\n",
    "# Sort rows by overall average improvement (descending)\n",
    "row_order = heatmap_data.mean(axis=1).sort_values(ascending=False).index\n",
    "heatmap_data = heatmap_data.loc[row_order]\n",
    "\n",
    "# Sort columns by overall average improvement (descending)\n",
    "col_order = heatmap_data.mean(axis=0).sort_values(ascending=False).index\n",
    "heatmap_data = heatmap_data[col_order]\n",
    "\n",
    "# Map language codes to full language names\n",
    "LANG_CODE_TO_NAME = {\n",
    "    'ar': 'Arabic', 'cs': 'Czech', 'de': 'German', 'es': 'Spanish',\n",
    "    'fr': 'French', 'hi': 'Hindi', 'hu': 'Hungarian', 'it': 'Italian',\n",
    "    'ja': 'Japanese', 'ko': 'Korean', 'nl': 'Dutch', 'pl': 'Polish',\n",
    "    'pt': 'Portuguese', 'ru': 'Russian', 'tr': 'Turkish', 'zh-cn': 'Chinese',\n",
    "    'all': 'All Languages',\n",
    "}\n",
    "heatmap_data.index = [LANG_CODE_TO_NAME.get(code.replace(\"_18089\", \"\").replace(\"_18108\", \"\").replace(\"_18118\", \"\"), code) for code in heatmap_data.index]\n",
    "\n",
    "\n",
    "custom_cmap = LinearSegmentedColormap.from_list('BrWtBl', ['#8B2500', '#E8742A', '#FFFFFF', '#7FB5D3', '#1F3B6E'])\n",
    "\n",
    "# Tighter limits for more extreme colors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=custom_cmap,\n",
    "    center=0,\n",
    "    vmin=-0.10,\n",
    "    vmax=0.6,\n",
    "    linewidths=0.5,\n",
    "    linecolor='white',\n",
    "    cbar_kws={'label': 'Improvement Rate'},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Primary Language', fontsize=18, fontweight='bold')\n",
    "ax.set_ylabel('Finetuning Language', fontsize=18, fontweight='bold')\n",
    "ax.set_title('Finetuned Improvement Rate by Training Language \u00d7 Primary Language',\n",
    "             fontsize=20, fontweight='bold', pad=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/finetuned_improvement_heatmap_lang_x_primary_language.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Heatmap: finetuned improvement rate by lang_code \u00d7 language_family\n",
    "# ============================================================================\n",
    "\n",
    "# Pivot the grouped means into a 2D matrix\n",
    "heatmap_data = (data_lang_merged\n",
    "    .groupby(['lang_code', 'answer'])['overall_improvement']\n",
    "    .mean()\n",
    "    .unstack(fill_value=np.nan))\n",
    "\n",
    "# Add whisper_base_im_on_all (finetuned on all languages) as an extra row\n",
    "base_all_model = MODEL_PAIRS['base']  # whisper_base_im_on_all\n",
    "base_all_rows = all_data[all_data['model'] == base_all_model].copy()\n",
    "base_baseline_rows = all_data[all_data['model'] == 'base'][['participant_id', 'answer', 'is_correct']].copy()\n",
    "base_baseline_rows = base_baseline_rows.rename(columns={'is_correct': 'base_is_correct'})\n",
    "base_all_merged = base_all_rows.merge(base_baseline_rows, on=['participant_id', 'answer'], how='left')\n",
    "base_all_merged['overall_improvement'] = base_all_merged['is_correct'].astype(int) - base_all_merged['base_is_correct'].astype(int)\n",
    "base_all_improvement = base_all_merged.groupby('answer')['overall_improvement'].mean()\n",
    "heatmap_data.loc['all'] = base_all_improvement\n",
    "\n",
    "heatmap_data = heatmap_data.round(2)\n",
    "\n",
    "# Sort rows by overall average improvement (descending)\n",
    "row_order = heatmap_data.mean(axis=1).sort_values(ascending=False).index\n",
    "heatmap_data = heatmap_data.loc[row_order]\n",
    "\n",
    "# Sort columns by overall average improvement (descending)\n",
    "col_order = heatmap_data.mean(axis=0).sort_values(ascending=False).index\n",
    "heatmap_data = heatmap_data[col_order]\n",
    "\n",
    "# Map language codes to full language names\n",
    "LANG_CODE_TO_NAME = {\n",
    "    'ar': 'Arabic', 'cs': 'Czech', 'de': 'German', 'es': 'Spanish',\n",
    "    'fr': 'French', 'hi': 'Hindi', 'hu': 'Hungarian', 'it': 'Italian',\n",
    "    'ja': 'Japanese', 'ko': 'Korean', 'nl': 'Dutch', 'pl': 'Polish',\n",
    "    'pt': 'Portuguese', 'ru': 'Russian', 'tr': 'Turkish', 'zh-cn': 'Chinese',\n",
    "    'all': 'All Languages',\n",
    "}\n",
    "heatmap_data.index = [LANG_CODE_TO_NAME.get(code.replace(\"_18089\", \"\").replace(\"_18108\", \"\").replace(\"_18118\", \"\"), code) for code in heatmap_data.index]\n",
    "\n",
    "\n",
    "custom_cmap = LinearSegmentedColormap.from_list('BrWtBl', ['#8B2500', '#E8742A', '#FFFFFF', '#7FB5D3', '#1F3B6E'])\n",
    "\n",
    "# Tighter limits for more extreme colors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=custom_cmap,\n",
    "    center=0,\n",
    "    vmin=-0.10,\n",
    "    vmax=0.6,\n",
    "    linewidths=0.5,\n",
    "    linecolor='white',\n",
    "    cbar_kws={'label': 'Improvement Rate'},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Speaker Language Family', fontsize=18, fontweight='bold')\n",
    "ax.set_ylabel('Finetuning Language', fontsize=18, fontweight='bold')\n",
    "ax.set_title('Finetuned Improvement Rate by Training Language \u00d7 Speaker Language Family',\n",
    "             fontsize=20, fontweight='bold', pad=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/finetuned_improvement_heatmap_lang_x_streetname.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc07c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ded1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15924b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}