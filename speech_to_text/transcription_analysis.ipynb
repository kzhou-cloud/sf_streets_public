{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6d1fc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Import all required libraries\n",
        "# ============================================================================\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import string\n",
        "import sys\n",
        "import textwrap\n",
        "import unicodedata\n",
        "\n",
        "sys.path.append('..')\n",
        "\n",
        "import jiwer\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from IPython.display import Audio, display, HTML\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from scipy import stats\n",
        "\n",
        "from utils import (\n",
        "    normalize_text,\n",
        "    process_primary_language,\n",
        "    categorize_language,\n",
        "    group_language_by_family,\n",
        "    check_english_only,\n",
        "    check_multilingual,\n",
        "    check_not_english,\n",
        "    read_transcription_data,\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "matplotlib.rcParams['font.family'] = 'Arial'\n",
        "matplotlib.rcParams['font.size'] = 24\n",
        "\n",
        "pd.set_option('display.max_rows', 20)\n",
        "\n",
        "# Set to small for quick testing, normally set to 10,000\n",
        "BOOTSTRAP_SAMPLES = 10000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affa8f87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all model families together\n",
        "MODEL_FAMILY = \"all\"\n",
        "\n",
        "# Model to model family mapping\n",
        "MODEL_TO_FAMILY = {\n",
        "    # Whisper models\n",
        "    'tiny': 'whisper',\n",
        "    'base': 'whisper',\n",
        "    'small': 'whisper', \n",
        "    'medium': 'whisper',\n",
        "    'large': 'whisper',\n",
        "\n",
        "    # Phi4 models\n",
        "    'phi-4-multimodal': 'phi4',\n",
        "    # Deepgram models\n",
        "    'nova-2': 'deepgram',\n",
        "    'nova-3': 'deepgram',\n",
        "    'enhanced-phonecall': 'deepgram',\n",
        "    'enhanced-general': 'deepgram',\n",
        "    'base-phonecall': 'deepgram',\n",
        "    'base-general': 'deepgram',\n",
        "    'telephony': 'deepgram',\n",
        "\n",
        "    # Google v2 models\n",
        "    'chirp_2': 'googlev2',\n",
        "    'chirp_3': 'googlev2',\n",
        "}\n",
        "\n",
        "# Define model sizes (in millions of parameters) for use in visualizations\n",
        "model_sizes = {\n",
        "    'tiny': 39,\n",
        "    'base': 74,\n",
        "    'small': 244,\n",
        "    'medium': 769,\n",
        "    'large': 1550,\n",
        "    'phi-4-multimodal': 14000,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31870028",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get list of allowed models (excluding finetuned models)\n",
        "allowed_models = list(MODEL_TO_FAMILY.keys())\n",
        "\n",
        "data = read_transcription_data(MODEL_FAMILY, allowed_models=allowed_models)\n",
        "\n",
        "\n",
        "\n",
        "street_origin = pd.read_csv(\"../street_names.tsv\")\n",
        "street_origin['name'] = street_origin['name'].str.lower()\n",
        "\n",
        "data = data.set_index(\"answer\").join(street_origin.set_index(\"name\"), how='left').reset_index()\n",
        "data.columns = ['answer', 'participant_id', 'index', 'model', 'prompt', 'original_text',\n",
        "       'transcription', 'transcription_og', 'Status', 'Primary language',\n",
        "       'Age', 'Sex', 'Language', 'english_only', 'multilingual', 'not_english',\n",
        "       'levenshtein_distance', 'is_correct', 'age_decade', 'origin']\n",
        "\n",
        "# Add model_family column based on model name\n",
        "data['model_family'] = data['model'].map(MODEL_TO_FAMILY)\n",
        "\n",
        "# Filter to only include models in MODEL_TO_FAMILY dictionary\n",
        "data = data[data['model'].isin(allowed_models)]\n",
        "print(f\"After filtering: {len(data)} rows, {data['model'].nunique()} unique models\")\n",
        "print(f\"Models included: {sorted(data['model'].unique())}\")\n",
        "\n",
        "data['language_group'] = data['Primary language'].apply(categorize_language)\n",
        "data['is_correct'] = data['is_correct'].astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e62b44",
      "metadata": {},
      "outputs": [],
      "source": [
        "#very noisy data // input error\n",
        "data = data[data['participant_id']!='PARTICIPANT_001']\n",
        "data = data[data['participant_id']!='PARTICIPANT_002']\n",
        "# To hear the audio files, go to the bottom of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fad0eea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deduplicate transcriptions (keep first occurrence of each participant/street/model/prompt)\n",
        "rows_before = len(data)\n",
        "data = data.drop_duplicates(subset=['participant_id', 'answer', 'model', 'prompt'], keep='first')\n",
        "print(f\"Deduplication: {rows_before:,} → {len(data):,} rows (removed {rows_before - len(data):,})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9edf8e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter prompts: only Whisper and Phi4 models should have non-\"No prompt\" transcriptions\n",
        "# For other models (Deepgram, Google), keep only \"No prompt\" transcriptions\n",
        "whisper_models = ['tiny', 'base', 'small', 'medium', 'large']\n",
        "phi4_models = ['phi-4-multimodal']\n",
        "models_with_all_prompts = whisper_models + phi4_models\n",
        "\n",
        "rows_before = len(data)\n",
        "# Keep rows where: (1) model is whisper/phi4, OR (2) prompt is \"No prompt\"\n",
        "data = data[(data['model'].isin(models_with_all_prompts)) | (data['prompt'] == 'No prompt')]\n",
        "print(f\"Prompt filtering: {rows_before:,} → {len(data):,} rows (removed {rows_before - len(data):,})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2abdf2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(data.groupby(\"participant_id\").sample(n=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f003f0ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Data quality checks\n",
        "#every model and every prompt should be the same number of participants 29*78\n",
        "pd.set_option('display.max_colwidth', 10)\n",
        "display(data.groupby([\"model\", \"prompt\"]).count().sort_values(\"is_correct\", ascending=False).reset_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ea7f18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add is_correct_prefix: Check if \"i'm on\" appears in original_text and transcription\n",
        "def check_prefix_correct(row):\n",
        "    \"\"\"Check if the prefix 'i'm on' is correctly transcribed (using normalized text with aliases) i am, i'm are marked as correct\"\"\"\n",
        "    if pd.isna(row['original_text']) or pd.isna(row['transcription']):\n",
        "        return np.nan\n",
        "    \n",
        "    # Use normalize_text to handle aliases and variations\n",
        "    original_normalized = normalize_text(row['original_text'])\n",
        "    transcription_normalized = normalize_text(row['transcription'])\n",
        "    \n",
        "    # Check if \"i'm on\" is in the original text\n",
        "    if \"i'm on\" in original_normalized:\n",
        "        # Check if it's also in the transcription\n",
        "        return float(\"i'm on\" in transcription_normalized)\n",
        "    else:\n",
        "        # If \"i'm on\" is not in original, it's a 0\n",
        "        return 0\n",
        "\n",
        "\n",
        "# Add is_correct_street_name: Check if the street name (answer) appears in the transcription\n",
        "def check_street_name_correct(row):\n",
        "    \"\"\"\n",
        "    Check if the street name appears correctly in the transcription (using normalized text with aliases)\n",
        "    Note: row['answer'] and row['transcription'] are already normalized in read_transcription_data\n",
        "    \"\"\"\n",
        "    if pd.isna(row['answer']):\n",
        "        return 0\n",
        "    \n",
        "    # The answer and transcription are already normalized via normalize_text in read_transcription_data\n",
        "    # So we can directly check if the answer appears in the transcription\n",
        "    answer = str(row['answer']).lower().strip()\n",
        "    transcription = str(row['transcription']).lower().strip()\n",
        "    \n",
        "    # Check if the street name appears in the transcription\n",
        "    return float(answer in transcription)\n",
        "\n",
        "# Add word error rate calculation using jiwer library\n",
        "def calculate_wer(row):\n",
        "    \"\"\"Calculate Word Error Rate (WER) between original text and transcription\"\"\"\n",
        "    if pd.isna(row['answer']) or pd.isna(row['transcription']):\n",
        "        return np.nan\n",
        "    \n",
        "    # Convert to string and strip whitespace\n",
        "    original = str(row['answer']).strip()\n",
        "    transcription = str(row['transcription']).strip()\n",
        "\n",
        "    wer = jiwer.wer(original, transcription)\n",
        "    return float(wer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e476698",
      "metadata": {},
      "source": [
        "## Numbers for paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9219754",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Analysis for no prompt\n",
        "\n",
        "no_prompt_df = data[data['prompt']=='No prompt'].copy()\n",
        "no_prompt_df['is_correct_prefix'] = no_prompt_df.apply(check_prefix_correct, axis=1)\n",
        "no_prompt_df['is_correct_street_name'] = no_prompt_df.apply(check_street_name_correct, axis=1)\n",
        "no_prompt_df['word_error_rate'] = no_prompt_df.apply(calculate_wer, axis=1)\n",
        "\n",
        "display(no_prompt_df.mean(numeric_only=True)[['is_correct', 'is_correct_street_name', 'is_correct_prefix', 'word_error_rate']])\n",
        "\n",
        "display(no_prompt_df.groupby(\"language_group\").mean(numeric_only=True)[['is_correct', 'is_correct_street_name', 'is_correct_prefix', 'word_error_rate']])\n",
        "\n",
        "display(no_prompt_df[no_prompt_df['model']=='large'].mean(numeric_only=True)[['is_correct', 'is_correct_street_name', 'is_correct_prefix', 'word_error_rate']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "754859cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "no_prompt_df.groupby(\"model\").mean(numeric_only=True)[['is_correct', 'is_correct_street_name', 'is_correct_prefix', 'word_error_rate']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08cd91b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Overall accuracy by prompt and language group\n",
        "data.groupby(['prompt', 'language_group']).mean(numeric_only=True)[['is_correct']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51e1f904",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.groupby(\"prompt\").mean(numeric_only=True)[['is_correct']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01caf7b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "participant_data = data.groupby(\"participant_id\").sample(n=1)\n",
        "\n",
        "for variable in [\"Sex\", \"age_decade\", \"language_group\"]:\n",
        "    display(participant_data.groupby(variable).count()[['answer']])\n",
        "    display(((participant_data.groupby(variable).count()/len(participant_data)).round(3)*100)[['answer']])\n",
        "    \n",
        "for variable in [\"Sex\", \"age_decade\", \"language_group\"]:\n",
        "    display(data.groupby([variable]).mean(numeric_only=True)[['is_correct']].round(3)*100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f66d7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "no_prompt_df.groupby(\"Sex\").mean(numeric_only=True)[['is_correct', 'is_correct_street_name', 'is_correct_prefix', 'word_error_rate']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e7435b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Total number of unique languages spoken by participants\n",
        "values = str([x.replace(\"'\", \"\").replace(\"'\", \"\")  for x in participant_data[\"Primary language\"].unique()]).split(\",\")\n",
        "values = [x.replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\") for x in values]\n",
        "\n",
        "print(\"Unique languages spoken by participants\", len(set(values)),  set(values))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cbf560",
      "metadata": {},
      "source": [
        "## Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de49deb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bootstrap sampling function with confidence intervals\n",
        "def bootstrap_accuracy(data, n_bootstrap=BOOTSTRAP_SAMPLES, confidence_level=0.95):\n",
        "    n = len(data)\n",
        "    if n == 0:\n",
        "        return {'mean': np.nan, 'lower': np.nan, 'upper': np.nan, 'std': np.nan}\n",
        "    \n",
        "    # Store bootstrap accuracies\n",
        "    bootstrap_accuracies = np.zeros(n_bootstrap)\n",
        "    \n",
        "    # Perform bootstrap sampling\n",
        "    for i in range(n_bootstrap):\n",
        "        # Sample with replacement\n",
        "        bootstrap_sample = data.sample(n=n, replace=True)\n",
        "        bootstrap_accuracies[i] = bootstrap_sample['is_correct'].mean()\n",
        "    \n",
        "    # Calculate confidence interval\n",
        "    alpha = 1 - confidence_level\n",
        "    lower_percentile = (alpha / 2) * 100\n",
        "    upper_percentile = (1 - alpha / 2) * 100\n",
        "    \n",
        "    ci_lower = np.percentile(bootstrap_accuracies, lower_percentile)\n",
        "    ci_upper = np.percentile(bootstrap_accuracies, upper_percentile)\n",
        "    \n",
        "    return {\n",
        "        'mean': data['is_correct'].mean(),\n",
        "        'lower': ci_lower,\n",
        "        'upper': ci_upper,\n",
        "        'std': np.std(bootstrap_accuracies)\n",
        "    }\n",
        "\n",
        "def calculate_bootstrap_by_model_group(data, n_bootstrap=BOOTSTRAP_SAMPLES):\n",
        "    results = []\n",
        "    \n",
        "    for (model, language_group), group_data in data.groupby(['model', 'language_group'], observed=True):\n",
        "        boot_result = bootstrap_accuracy(group_data, n_bootstrap=n_bootstrap)\n",
        "        results.append({\n",
        "            'model': model,\n",
        "            'language_group': language_group,\n",
        "            'mean': boot_result['mean'],\n",
        "            'lower': boot_result['lower'],\n",
        "            'upper': boot_result['upper'],\n",
        "            'std': boot_result['std']\n",
        "        })\n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df['model_size'] = results_df['model'].map(model_sizes)\n",
        "    \n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fdba21c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization with bootstrap confidence bands\n",
        "\n",
        "def visualize_data_with_confidence_bands(data, ax, prompt, n_bootstrap=10000, colors=None):\n",
        "    \"\"\"\n",
        "    Visualize accuracy data with 95% confidence bands using bootstrap sampling.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : DataFrame\n",
        "        Data to visualize\n",
        "    ax : matplotlib axis\n",
        "        Axis to plot on\n",
        "    prompt : str\n",
        "        Prompt text for the title\n",
        "    n_bootstrap : int\n",
        "        Number of bootstrap samples (default: 10000)\n",
        "    colors : dict\n",
        "        Colors for each language group (default: None, uses default colors)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Add language group\n",
        "    data['language_group'] = data['Primary language'].apply(categorize_language)\n",
        "    \n",
        "    # Calculate bootstrap confidence intervals\n",
        "    print(f\"Calculating bootstrap confidence intervals for: {prompt[:50]}...\")\n",
        "    bootstrap_results = calculate_bootstrap_by_model_group(data, n_bootstrap=n_bootstrap)\n",
        "    \n",
        "    # Define colors for the three groups (darkest = Non-English, lightest = English only)\n",
        "    if colors is None:\n",
        "        colors = {'English only': '#59A14F', 'Multilingual (English)': '#76B7B2', 'Non-English': '#E15759'}\n",
        "    \n",
        "    # Filter to only models with sizes in model_sizes\n",
        "    bootstrap_results = bootstrap_results.dropna(subset=['model_size'])\n",
        "    \n",
        "    # Use log scale for x-axis\n",
        "    ax.set_xscale('log')\n",
        "    \n",
        "    # Plot each language group as a separate line with confidence bands\n",
        "    for language_group in ['English only', 'Multilingual (English)', 'Non-English']:\n",
        "        group_data = bootstrap_results[bootstrap_results['language_group'] == language_group]\n",
        "        # Sort by model size and reset index to ensure proper alignment\n",
        "        group_data = group_data.sort_values('model_size').reset_index(drop=True)\n",
        "        \n",
        "        if len(group_data) > 0:\n",
        "            # Use model sizes for x positions\n",
        "            x = group_data['model_size'].values\n",
        "            y_mean = group_data['mean'].values\n",
        "            y_lower = group_data['lower'].values\n",
        "            y_upper = group_data['upper'].values\n",
        "            \n",
        "            # Plot confidence band (shaded area)\n",
        "            ax.fill_between(x, y_lower, y_upper, alpha=0.2, color=colors[language_group])\n",
        "            \n",
        "            # Plot line (lighter)\n",
        "            ax.plot(x, y_mean, linewidth=2, alpha=0.3, color=colors[language_group])\n",
        "            \n",
        "            # Plot markers with full opacity\n",
        "            ax.plot(x, y_mean, marker='o', linewidth=0, markersize=8, \n",
        "                    color=colors[language_group], label=language_group)\n",
        "    \n",
        "    \n",
        "    ax.set_xlabel('Model Size (Millions of Parameters)', fontsize=12)\n",
        "    ax.set_ylabel('Accuracy', fontsize=12)\n",
        "    \n",
        "    # Wrap title to multiple lines if needed\n",
        "    wrapped_title = '\\n'.join(textwrap.wrap(prompt[:80], width=50))\n",
        "    ax.set_title(wrapped_title, fontsize=14)\n",
        "    \n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.set_xlim(25, 20000)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1a11fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create plot with 3 subplots and confidence bands\n",
        "print(\"Creating visualization with bootstrap confidence bands...\")\n",
        "print(\"Note: This may take a few minutes due to 10,000 bootstrap samples per group.\\n\")\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots(figsize=(15, 6), nrows=1, ncols=3)\n",
        "\n",
        "\n",
        "# Get unique prompts, filtering out NaN values, and sort\n",
        "unique_prompts = sorted([p for p in data['prompt'].unique() if pd.notna(p)])\n",
        "for n, prompt in enumerate(unique_prompts):\n",
        "    visualize_data_with_confidence_bands(data[data['prompt'] == prompt], axes[n], prompt, n_bootstrap=BOOTSTRAP_SAMPLES)\n",
        "\n",
        "# Update axis labels to match style\n",
        "for ax in axes:\n",
        "    ax.set_xlabel('Model Size (Millions of Parameters)', fontsize=14)\n",
        "    ax.set_ylabel('Average Accuracy', fontsize=14)\n",
        "\n",
        "# Create a single shared legend below all subplots\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, title='Language Group', \n",
        "           bbox_to_anchor=(0.5, -0.02), loc='upper center', ncol=3, \n",
        "           frameon=True, fontsize=12, title_fontsize=12)\n",
        "\n",
        "fig.suptitle('Transcription Accuracy by Prompt Type w/ 95% CI', fontsize=16, y=1.02)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "output_dir = \"figures\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get model names from the data\n",
        "model_names = \"_\".join(sorted(data['model'].unique()))\n",
        "output_filename = f\"all_models_accuracy_{model_names}.pdf\"\n",
        "output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "plt.savefig(f'figures/accuracy_by_figure_2.png', dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n✓ Saved high-quality PDF to: {output_path}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Visualization complete with 95% bootstrap confidence intervals!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbd8830",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single graph with three lines - one for each prompt type\n",
        "# Shows average performance across all language groups\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Get unique prompts\n",
        "unique_prompts = sorted([p for p in data['prompt'].unique()])\n",
        "\n",
        "# Define colors for each prompt\n",
        "prompt_colors = ['#2E86AB', '#F18F01', '#A23B72']\n",
        "prompt_labels = ['No prompt', 'Prompt - The user is going to give you their location via an address ', 'The user is going to give you their location via one of the following addresses:...']\n",
        "\n",
        "ax.set_xscale('log')\n",
        "\n",
        "for idx, prompt in enumerate(unique_prompts):\n",
        "    prompt_data = data[data['prompt'] == prompt].copy()\n",
        "    \n",
        "    # Calculate average accuracy by model (across all language groups)\n",
        "    model_accuracy = prompt_data.groupby('model').agg({\n",
        "        'is_correct': 'mean'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Add model sizes\n",
        "    model_accuracy['model_size'] = model_accuracy['model'].map(model_sizes)\n",
        "    model_accuracy = model_accuracy.dropna(subset=['model_size'])\n",
        "    model_accuracy = model_accuracy.sort_values('model_size')\n",
        "    \n",
        "    # Calculate bootstrap CI for each model\n",
        "    ci_results = []\n",
        "    for model in model_accuracy['model'].unique():\n",
        "        model_data = prompt_data[prompt_data['model'] == model]\n",
        "        if len(model_data) > 0:\n",
        "            boot_result = bootstrap_accuracy(model_data, n_bootstrap=BOOTSTRAP_SAMPLES)\n",
        "            ci_results.append({\n",
        "                'model': model,\n",
        "                'model_size': model_sizes.get(model, np.nan),\n",
        "                'mean': boot_result['mean'],\n",
        "                'lower': boot_result['lower'],\n",
        "                'upper': boot_result['upper']\n",
        "            })\n",
        "    \n",
        "    ci_df = pd.DataFrame(ci_results).dropna(subset=['model_size']).sort_values('model_size')\n",
        "    \n",
        "    if len(ci_df) > 0:\n",
        "        x = ci_df['model_size'].values\n",
        "        y_mean = ci_df['mean'].values\n",
        "        y_lower = ci_df['lower'].values\n",
        "        y_upper = ci_df['upper'].values\n",
        "        \n",
        "        # Plot confidence band\n",
        "        ax.fill_between(x, y_lower, y_upper, alpha=0.2, color=prompt_colors[idx])\n",
        "        \n",
        "        # Plot line\n",
        "        ax.plot(x, y_mean, marker='o', linewidth=2, markersize=8, \n",
        "                color=prompt_colors[idx], label=prompt_labels[idx] if idx < len(prompt_labels) else prompt[:30])\n",
        "        \n",
        "        # Add model labels (only for first prompt to avoid clutter)\n",
        "        if idx == 0:\n",
        "            label_y = 0.98  # Fixed y-coordinate for all labels\n",
        "            for i, row in ci_df.iterrows():\n",
        "                # Draw vertical line from label to data point\n",
        "                ax.plot([row['model_size'], row['model_size']], [row['mean'], label_y - 0.07], \n",
        "                       color='gray', linewidth=0.5, linestyle='-', alpha=0.5)\n",
        "                # Add label at fixed y position\n",
        "                ax.text(row['model_size'], label_y - 0.07, row['model'], \n",
        "                       ha='center', va='bottom', fontsize=14, rotation=30)\n",
        "\n",
        "# Add dashed horizontal lines for average accuracy of each prompt\n",
        "for idx, prompt in enumerate(unique_prompts):\n",
        "    prompt_data = data[data['prompt'] == prompt]\n",
        "    avg_accuracy = prompt_data['is_correct'].mean()\n",
        "    ax.axhline(y=avg_accuracy, color=prompt_colors[idx], linestyle='--', linewidth=.7, alpha=0.7)\n",
        "    # Add label on right side\n",
        "    ax.text(22000, avg_accuracy, f'{avg_accuracy:.2f}', \n",
        "            color=prompt_colors[idx], fontsize=14, va='center')\n",
        "\n",
        "ax.set_xlabel('Model Size in Millions of Parameters (Log Scale)', fontsize=14)\n",
        "ax.set_ylabel('Average Accuracy', fontsize=14)\n",
        "ax.set_title('Transcription Accuracy by Prompt Type w/ 95% CI', \n",
        "             fontsize=16)\n",
        "ax.set_ylim(0, 1.0)\n",
        "ax.set_xlim(25, 20000)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(title='Prompt Type', fontsize=12, title_fontsize=12, loc='lower right')\n",
        "\n",
        "plt.savefig(f'figures/overall_accuracies_figure_1.png', dpi=150, bbox_inches='tight')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d7f2a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate grouped means\n",
        "grouped_means = no_prompt_df.groupby(['model', 'language_group']).mean(numeric_only=True).sort_values('is_correct', ascending=False)[['is_correct']]\n",
        "\n",
        "# Calculate confidence intervals for each group using bootstrap_accuracy function from Cell 10\n",
        "ci_results = []\n",
        "for (model, language_group), group_data in no_prompt_df.groupby(['model', 'language_group'], observed=True):\n",
        "    boot_result = bootstrap_accuracy(group_data, n_bootstrap=10)\n",
        "    ci_results.append({\n",
        "        'model': model,\n",
        "        'language_group': language_group,\n",
        "        'mean': boot_result['mean'],\n",
        "        'ci_lower': boot_result['lower'],\n",
        "        'ci_upper': boot_result['upper'],\n",
        "        'error_lower': boot_result['mean'] - boot_result['lower'],\n",
        "        'error_upper': boot_result['upper'] - boot_result['mean'],\n",
        "        'n': len(group_data),\n",
        "        'std': boot_result['std']\n",
        "    })\n",
        "\n",
        "ci_df = pd.DataFrame(ci_results)\n",
        "\n",
        "# Add model_family to ci_df\n",
        "ci_df['model_family'] = ci_df['model'].map(MODEL_TO_FAMILY)\n",
        "ci_df = ci_df.sort_values(by='mean', ascending=True)\n",
        "\n",
        "# Get unique model families (excluding NaN)\n",
        "model_families = [f for f in ci_df['model_family'].unique() if pd.notna(f)]\n",
        "\n",
        "# Define colors for language groups\n",
        "colors = {\n",
        "    'English only': '#2E86AB', \n",
        "    'Multilingual (English)': '#F18F01', \n",
        "    'Non-English': '#A23B72'\n",
        "}\n",
        "language_groups = ['English only', 'Multilingual (English)', 'Non-English']\n",
        "\n",
        "# Create single figure with horizontal subplots scaled by number of models\n",
        "n_families = len(model_families)\n",
        "\n",
        "# Calculate width ratios based on number of models in each family\n",
        "width_ratios = [len(ci_df[ci_df['model_family'] == f]['model'].unique()) for f in model_families]\n",
        "total_models = sum(width_ratios)\n",
        "\n",
        "fig, axes = plt.subplots(1, n_families, figsize=(1.2 * total_models, 8), sharey=True,\n",
        "                         gridspec_kw={'width_ratios': width_ratios})\n",
        "if n_families == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "width = 0.25\n",
        "offsets = np.array([-width, 0, width])\n",
        "\n",
        "for idx, family in enumerate(model_families):\n",
        "    ax = axes[idx]\n",
        "    family_df = ci_df[ci_df['model_family'] == family]\n",
        "    models = family_df['model'].unique()\n",
        "    \n",
        "    # Set up bar positions\n",
        "    n_models = len(models)\n",
        "    x = np.arange(n_models)\n",
        "    \n",
        "    # Plot bars for each language group\n",
        "    for i, lang_group in enumerate(language_groups):\n",
        "        group_data = family_df[family_df['language_group'] == lang_group].copy()\n",
        "        group_data = group_data.set_index('model').reindex(models).reset_index()\n",
        "        \n",
        "        bars = ax.bar(x + offsets[i], \n",
        "                      group_data['mean'], \n",
        "                      width, \n",
        "                      label=lang_group,\n",
        "                      color=colors[lang_group],\n",
        "                      alpha=0.8,\n",
        "                      edgecolor='white',\n",
        "                      linewidth=1.5)\n",
        "        \n",
        "        \n",
        "        # Only plot error bars for non-NaN values\n",
        "        valid_mask = ~group_data['mean'].isna()\n",
        "        if valid_mask.any():\n",
        "            ax.errorbar(x[valid_mask] + offsets[i], \n",
        "                        group_data.loc[valid_mask, 'mean'],\n",
        "                        yerr=[group_data.loc[valid_mask, 'error_lower'].fillna(0), \n",
        "                              group_data.loc[valid_mask, 'error_upper'].fillna(0)],\n",
        "                        fmt='none',\n",
        "                        ecolor='black',\n",
        "                        elinewidth=0.7,\n",
        "                        capsize=4,\n",
        "                        capthick=0.7,\n",
        "                        alpha=0.7)\n",
        "    \n",
        "    \n",
        "    ax.set_title(f'{family.upper()}', fontsize=16)\n",
        "    # ax.set_xlabel('Model', fontsize=14)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(models, fontsize=12, rotation=45, ha='right')\n",
        "    \n",
        "\n",
        "    ax.set_xlim(-0.5, n_models - 0.5)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.set_ylim(0, 1.0)\n",
        "\n",
        "# Only add y-label to first subplot\n",
        "axes[0].set_ylabel('Accuracy (Mean ± 95% CI)', fontsize=14)\n",
        "\n",
        "# Add shared legend\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "leg = fig.legend(handles, labels, title='Primary Language', loc='upper center', \n",
        "           bbox_to_anchor=(0.5, 0.97), ncol=3, fontsize=11, title_fontsize=11,\n",
        "           columnspacing=2, handletextpad=0.8, frameon=True, fancybox=False,\n",
        "           edgecolor='gray', facecolor='white', framealpha=1.0)\n",
        "leg.get_frame().set_linewidth(0.5)\n",
        "\n",
        "fig.suptitle('Transcription Accuracy by Model Family and Language Group\\n(with 95% Bootstrap Confidence Intervals)', \n",
        "             fontsize=14, y=1.02)\n",
        "plt.savefig(f'figures/potential_figure_2.png', dpi=150, bbox_inches='tight')\n",
        "plt.subplots_adjust(wspace=0.15, left=0.06, right=0.98, bottom=0.18, top=0.85)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96fe12e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for heatmap\n",
        "grouped_data = no_prompt_df.groupby([\"answer\", \"Primary language\"]).mean(numeric_only=True)[['is_correct']]\n",
        "\n",
        "# Pivot the data for heatmap (Primary language as rows, answer as columns)\n",
        "heatmap_data = grouped_data.reset_index().pivot(index='Primary language', columns='answer', values='is_correct')\n",
        "\n",
        "# Sort y-axis by average accuracy across all streets (descending)\n",
        "heatmap_data['_avg_row'] = heatmap_data.mean(axis=1)\n",
        "heatmap_data = heatmap_data.sort_values('_avg_row', ascending=False)\n",
        "heatmap_data = heatmap_data.drop('_avg_row', axis=1)\n",
        "\n",
        "# Sort x-axis by average accuracy across all languages (descending)\n",
        "col_averages = heatmap_data.mean(axis=0).sort_values(ascending=False)\n",
        "heatmap_data = heatmap_data[col_averages.index]\n",
        "\n",
        "# Create the heatmap\n",
        "fig, ax = plt.subplots(figsize=(18, 6))\n",
        "sns.heatmap(heatmap_data, annot=False, cmap='RdYlGn', center=0.5, \n",
        "            vmin=0, vmax=1, cbar_kws={'label': 'Accuracy'}, \n",
        "            linewidths=0.5, linecolor='gray', ax=ax)\n",
        "ax.set_title('Transcription Accuracy by Street Name and Language', fontsize=16, pad=15)\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('Language', fontsize=12)\n",
        "# Clean up y-tick labels: remove \"English\" unless it's the only language\n",
        "ytick_labels = [label.get_text() for label in ax.get_yticklabels()]\n",
        "cleaned_labels = []\n",
        "for label in ytick_labels:\n",
        "    if label.lower().strip() == 'english':\n",
        "        cleaned_labels.append(label)\n",
        "    else:\n",
        "        # Remove \"English, \" or \", English\" from the label\n",
        "        cleaned = label.replace('English, ', '').replace(', English', '')\n",
        "        cleaned_labels.append(cleaned)\n",
        "ax.set_yticklabels(cleaned_labels, fontsize=10)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
        "\n",
        "plt.subplots_adjust(left=0.15, right=0.95, top=0.92, bottom=0.25)\n",
        "plt.savefig(f'figures/all_models_accuracy_by_street_language.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21259fe3",
      "metadata": {},
      "outputs": [],
      "source": [
        "lep_data = pd.read_csv(\"population_by_language.tsv\", sep=\"\\t\")\n",
        "lep_data = lep_data[['Language', 'LEP_Population']] \n",
        "lep_data['LEP_Population'] = lep_data['LEP_Population'].astype(int)\n",
        "lep_data['LEP_Population_Percent'] = lep_data['LEP_Population'] / 151388\n",
        "lep_data = lep_data.sort_values('LEP_Population_Percent', ascending=False)\n",
        "\n",
        "# Create visualization\n",
        "fig, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Tableau 20 for more distinct colors\n",
        "colors = plt.cm.tab20.colors[:len(lep_data)]\n",
        "\n",
        "# Create pie chart without labels (we'll add them with lines)\n",
        "wedges, texts = ax.pie(\n",
        "    lep_data['LEP_Population'], \n",
        "    colors=colors,\n",
        "    startangle=90,\n",
        "    radius=0.6,\n",
        "    wedgeprops={'linewidth': 2, 'edgecolor': 'white'}\n",
        ")\n",
        "\n",
        "# Add labels with leader lines\n",
        "bbox_props = dict(boxstyle=\"square,pad=0.15\", fc=\"white\", ec=\"none\", alpha=0.8)\n",
        "\n",
        "for i, (wedge, (lang, pop, pct)) in enumerate(zip(wedges, \n",
        "    zip(lep_data['Language'], lep_data['LEP_Population'], lep_data['LEP_Population_Percent']))):\n",
        "    \n",
        "    # Skip labels for slices under 1%\n",
        "    if pct < 0.03:\n",
        "        continue\n",
        "    \n",
        "    ang = (wedge.theta2 - wedge.theta1) / 2. + wedge.theta1\n",
        "    x = np.cos(np.deg2rad(ang))\n",
        "    y = np.sin(np.deg2rad(ang))\n",
        "    \n",
        "    # Position labels outside the pie\n",
        "    horizontalalignment = \"left\" if x >= 0 else \"right\"\n",
        "    \n",
        "    # Label text: include population count\n",
        "    # Split long labels onto multiple lines\n",
        "    if lang == \"Other Asian and Pacific Island languages\":\n",
        "        lang = \"Other Asian&\\nPacific Island languages\"\n",
        "    \n",
        "    \n",
        "    # Calculate label position (adjusted for smaller pie)\n",
        "    label_x = 0.8 * x\n",
        "    label_y = .95* y\n",
        "    \n",
        "    # Adjust specific labels\n",
        "    if \"Russian\" in lang or \"Slavic\" in lang:\n",
        "        label_x = 0.0  # More to the right (east)\n",
        "        label_y = 0.9 # Higher up (north)\n",
        "    \n",
        "    # Add language name (bold) with leader line\n",
        "    ax.annotate(lang, \n",
        "                xy=(x * 0.6, y * 0.6),  # Point on pie edge\n",
        "                xytext=(label_x, label_y),\n",
        "                horizontalalignment=horizontalalignment,\n",
        "                fontsize=18, fontweight='bold',\n",
        "                arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.8),\n",
        "                bbox=bbox_props)\n",
        "    \n",
        "    # Add population (regular weight) below the language name\n",
        "    pop_offset = -0.06 if lang.count('\\n') == 0 else -0.09\n",
        "    ax.text(label_x, label_y + pop_offset, f\"Population: {pop:,}\",\n",
        "            horizontalalignment=horizontalalignment,\n",
        "            fontsize=12, fontweight='normal', color='#555')\n",
        "\n",
        "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "plt.savefig('figures/LEP_SF.png', dpi=200, bbox_inches='tight', pad_inches=0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f1a0b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Play audio samples from the 2 participants who were filtered due to noisy data\n",
        "\n",
        "filtered_participants = {\n",
        "    'PARTICIPANT_001': 'Participant 1',\n",
        "    'PARTICIPANT_002': 'Participant 2', \n",
        "}\n",
        "\n",
        "def play_audio_samples_from_filtered_participants(n_samples=3, audio_dir='audio_files'):\n",
        "    \"\"\"\n",
        "    Display audio samples from participants who were filtered due to noisy data.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_samples : int\n",
        "        Number of audio samples to display per participant (default: 3)\n",
        "    audio_dir : str\n",
        "        Directory containing audio files (default: 'audio_files')\n",
        "    \"\"\"\n",
        "    \n",
        "    display(HTML(\"<h2>Audio Samples from Filtered Participants (Noisy Data)</h2>\"))\n",
        "    \n",
        "    for pid, label in filtered_participants.items():\n",
        "        # Find audio files for this participant\n",
        "        pattern = os.path.join(audio_dir, f\"{pid}_*.webm\")\n",
        "        audio_files = sorted(glob.glob(pattern))\n",
        "        \n",
        "        if not audio_files:\n",
        "            print(f\"\\n{label} ({pid}): No audio files found\")\n",
        "            continue\n",
        "        \n",
        "        display(HTML(f\"<h3>{label} - {pid}</h3>\"))\n",
        "        display(HTML(f\"<p><b>Total audio files:</b> {len(audio_files)}</p>\"))\n",
        "        \n",
        "        # Play first n_samples\n",
        "        samples_to_play = audio_files[:n_samples]\n",
        "        \n",
        "        for i, audio_file in enumerate(samples_to_play, 1):\n",
        "            # Extract street name from filename\n",
        "            filename = os.path.basename(audio_file)\n",
        "            # Format: participant_id_uuid_streetname.webm or participant_id_uuid.oga_streetname.webm\n",
        "            street_name = filename.split('_')[-1].replace('.webm', '').replace('_', ' ').title()\n",
        "            \n",
        "            display(HTML(f\"<p><b>Sample {i}/{len(samples_to_play)}:</b> {street_name}</p>\"))\n",
        "            display(Audio(audio_file))\n",
        "        \n",
        "        display(HTML(\"<hr>\"))\n",
        "\n",
        "# Display audio samples (3 per participant by default)\n",
        "play_audio_samples_from_filtered_participants(n_samples=3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
