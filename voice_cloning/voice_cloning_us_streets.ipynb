{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Voice Cloning with XTTS-v2\n",
        "\n",
        "This notebook demonstrates voice cloning and text-to-speech generation using the [Coqui XTTS-v2](https://huggingface.co/coqui/XTTS-v2) model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import os\n",
        "import random as _rng\n",
        "import re\n",
        "import subprocess\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "# Third-party\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from IPython.display import Audio, display, HTML\n",
        "from TTS.api import TTS\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "\n",
        "# Project settings\n",
        "PROJECT_DIR = \"all_us_streets\"  # Output directory for generated audio\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_SEED = 153\n",
        "\n",
        "# Language filter: \"all\" for all languages, or specific code like \"es\", \"fr\", \"de\"\n",
        "FILTER_LANGUAGE = \"all\"\n",
        "\n",
        "# Client ID length for filenames\n",
        "CLIENT_ID_SHORT_LENGTH = 8\n",
        "\n",
        "# Translations of \"Hello, my name is ...\" for each language (via Google Translate)\n",
        "LANGUAGE_TO_PREFIX = {\n",
        "    \"hi\": \"नमस्ते, मेरा नाम है... \",      # Hindi\n",
        "    \"ko\": \"안녕하세요, 제 이름은... \",       # Korean\n",
        "    \"hu\": \"Helló, a nevem... \",           # Hungarian\n",
        "    \"cs\": \"Ahoj, jmenuji se... \",         # Czech\n",
        "    \"tr\": \"Merhaba, benim adım... \",      # Turkish\n",
        "    \"zh-cn\": \"你好，我的名字是... \",        # Chinese\n",
        "    \"nl\": \"Hallo, mijn naam is... \",      # Dutch\n",
        "    \"ja\": \"こんにちは、私の名前は... \",      # Japanese\n",
        "    \"pl\": \"Cześć, mam na imię... \",       # Polish\n",
        "    \"ar\": \"مرحباً، اسمي... \",             # Arabic\n",
        "    \"pt\": \"Olá, meu nome é... \",          # Portuguese\n",
        "    \"it\": \"Ciao, mi chiamo... \",          # Italian\n",
        "    \"ru\": \"Привет, меня зовут... \",       # Russian\n",
        "    \"de\": \"Hallo, mein Name ist... \",     # German\n",
        "    \"fr\": \"Bonjour, je m'appelle... \",    # French\n",
        "    \"es\": \"Hola, mi nombre es... \",       # Spanish\n",
        "}\n",
        "\n",
        "# Translations of \"... finish.\" for each language (via Google Translate)\n",
        "LANGUAGE_TO_SUFFIX = {\n",
        "    \"hi\": \"... समाप्त।\",      # Hindi\n",
        "    \"ko\": \"... 끝.\",          # Korean\n",
        "    \"hu\": \"... vége.\",        # Hungarian\n",
        "    \"cs\": \"... konec.\",       # Czech\n",
        "    \"tr\": \"... bitiş.\",       # Turkish\n",
        "    \"zh-cn\": \"... 结束。\",     # Chinese\n",
        "    \"nl\": \"... einde.\",       # Dutch\n",
        "    \"ja\": \"... 終わり。\",      # Japanese\n",
        "    \"pl\": \"... koniec.\",      # Polish\n",
        "    \"ar\": \"... انتهى.\",       # Arabic\n",
        "    \"pt\": \"... fim.\",         # Portuguese\n",
        "    \"it\": \"... fine.\",        # Italian\n",
        "    \"ru\": \"... конец.\",       # Russian\n",
        "    \"de\": \"... Ende.\",        # German\n",
        "    \"fr\": \"... fin.\",         # French\n",
        "    \"es\": \"... fin.\",         # Spanish\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "PROJECT_DIR = \"all_us_streets\"  # <-- CHANGE THIS FOR DIFFERENT PROJECTS\n",
        "streets_df = pd.read_csv(\"../street_names_dataset/street_names_100_per_city_random_state_589208.tsv\", sep='\\t')\n",
        "streets_df = streets_df[['street_name']]\n",
        "streets_df.columns = ['name']\n",
        "# Keep only single-word street names (no spaces)\n",
        "streets_df = streets_df[~streets_df['name'].str.contains(' ')].reset_index(drop=True)\n",
        "print(f\"{len(streets_df)} single-word street names to generate (1 file each, random speaker)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Compatibility Patches for Model Loading\n",
        "# ============================================================================\n",
        "\n",
        "def _patched_torchaudio_load(filepath, *args, **kwargs):\n",
        "    \"\"\"Load audio using soundfile instead of torchcodec (avoids FFmpeg 8 issue).\"\"\"\n",
        "    data, sr = sf.read(filepath)\n",
        "    if data.ndim == 1:\n",
        "        data = data.reshape(1, -1)\n",
        "    else:\n",
        "        data = data.T\n",
        "    return torch.from_numpy(data.astype(np.float32)), sr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Device Setup & Model Loading\n",
        "# ============================================================================\n",
        "\n",
        "# Check available device\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "    print(\"Using Apple Silicon GPU (MPS)\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU (this will be slower)\")\n",
        "\n",
        "# Agree to Coqui license terms (non-commercial CPML)\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "# Apply compatibility patches\n",
        "_original_torch_load = torch.load\n",
        "_original_torchaudio_load = torchaudio.load\n",
        "torch.load = lambda *args, **kwargs: _original_torch_load(*args, **{**kwargs, 'weights_only': False})\n",
        "torchaudio.load = _patched_torchaudio_load\n",
        "\n",
        "# Load XTTS-v2 model\n",
        "print(\"\\nLoading XTTS-v2 model...\")\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
        "tts.to(device)\n",
        "\n",
        "# Restore torch.load but keep torchaudio.load patched\n",
        "# (the patched version avoids FFmpeg/torchcodec errors during generation)\n",
        "torch.load = _original_torch_load\n",
        "# NOTE: torchaudio.load is intentionally left patched so that\n",
        "# tts_to_file() calls during generation don't hit the torchcodec error.\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# streets_df, FILTER_LANGUAGE, and other config are now in Configuration cell (cell 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load XTTS supported languages and their codes from CSV\n",
        "df_languages = pd.read_csv('xtts_supported_languages.csv')\n",
        "\n",
        "# Create mappings between language names and codes\n",
        "LANGUAGE_TO_CODE = dict(zip(df_languages['Language'], df_languages['Code']))\n",
        "CODE_TO_LANGUAGE = dict(zip(df_languages['Code'], df_languages['Language']))\n",
        "\n",
        "print(f\"Loaded {len(df_languages)} XTTS supported languages\")\n",
        "print(df_languages)\n",
        "\n",
        "# Base path for random sample clips\n",
        "CV_BASE_PATH = Path(\"random_sample_clips\")\n",
        "\n",
        "def load_random_sample_clips(base_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Load audio clips and metadata from random_sample_clips directory.\n",
        "    \n",
        "    Expects each language folder to contain:\n",
        "    - Audio files (.mp3, .wav, etc.)\n",
        "    - validated.tsv file with metadata (from Common Voice)\n",
        "    \"\"\"\n",
        "    all_dfs = []\n",
        "    \n",
        "    # Iterate through language folders\n",
        "    for lang_folder in base_path.iterdir():\n",
        "        if not lang_folder.is_dir():\n",
        "            continue\n",
        "            \n",
        "        language_name = lang_folder.name\n",
        "        language_code = LANGUAGE_TO_CODE.get(language_name, language_name.lower()[:2])\n",
        "        \n",
        "        # Load metadata from validated.tsv (required)\n",
        "        validated_tsv = lang_folder / \"validated.tsv\"\n",
        "        \n",
        "        if not validated_tsv.exists():\n",
        "            print(f\"Skipping {language_name}: no validated.tsv found\")\n",
        "            continue\n",
        "        \n",
        "        # Load clips with metadata\n",
        "        df = pd.read_csv(validated_tsv, sep='\\t')\n",
        "        df['language'] = language_code\n",
        "        df['language_name'] = language_name\n",
        "        df['file_path'] = df['path'].apply(lambda x: str(lang_folder / x))\n",
        "        all_dfs.append(df)\n",
        "        print(f\"Loaded {len(df):,} clips from {language_name} ({language_code})\")\n",
        "    \n",
        "    if not all_dfs:\n",
        "        print(\"No clips loaded!\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(f\"\\nTotal: {len(combined_df):,} clips across {len(all_dfs)} languages\")\n",
        "    \n",
        "    return combined_df\n",
        "\n",
        "# Load all clips\n",
        "cv_metadata_df = load_random_sample_clips(CV_BASE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display dataframe info\n",
        "print(f\"\\nDataFrame shape: {cv_metadata_df.shape}\")\n",
        "\n",
        "# Show clips per language\n",
        "print(\"\\nAvailable Clips per language:\")\n",
        "print(cv_metadata_df.groupby(['language', 'language_name']).size().reset_index(name='count'))\n",
        "\n",
        "# Show sample of the dataframe (only show columns that exist)\n",
        "print(\"\\nSample data:\")\n",
        "display_cols = ['path', 'language', 'language_name']\n",
        "optional_cols = ['sentence', 'gender', 'age', 'duration_ms', 'client_id']\n",
        "display_cols.extend([col for col in optional_cols if col in cv_metadata_df.columns])\n",
        "cv_metadata_df[display_cols].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter and shuffle clips for processing\n",
        "\n",
        "def filter_and_shuffle_clips(df: pd.DataFrame, seed: int, \n",
        "                             filter_language: str = None) -> pd.DataFrame:\n",
        "    \"\"\"Filter clips by language and shuffle them randomly.\n",
        "    \n",
        "    This prepares all clips for processing by optionally filtering to a specific\n",
        "    language and then shuffling the order for randomized processing.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with clips metadata (must have 'language' column)\n",
        "        seed: Random seed for reproducibility\n",
        "        filter_language: Optional language code to filter to (e.g., \"de\", \"fr\"). \n",
        "                        If None or \"all\", uses all languages.\n",
        "    \"\"\"\n",
        "    # Filter by language if specified\n",
        "    if filter_language and filter_language.lower() != \"all\":\n",
        "        original_len = len(df)\n",
        "        df = df[df['language'] == filter_language].copy()\n",
        "        print(f\"Filtered to language '{filter_language}': {original_len} → {len(df)} clips\")\n",
        "\n",
        "    return df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Filter and shuffle clips (uses FILTER_LANGUAGE from config cell)\n",
        "sampled_clips_df = filter_and_shuffle_clips(cv_metadata_df, RANDOM_SEED, filter_language=FILTER_LANGUAGE)\n",
        "sampled_clips_df = sampled_clips_df.groupby(\"language\").head(3)\n",
        "\n",
        "# Show stats\n",
        "print(\"Clips per language:\")\n",
        "if 'client_id' in sampled_clips_df.columns:\n",
        "    print(sampled_clips_df.groupby(['language', 'language_name']).agg(\n",
        "        unique_clients=('client_id', 'nunique'),\n",
        "        total_clips=('path', 'count')\n",
        "    ).reset_index())\n",
        "    print(f\"\\nTotal: {len(sampled_clips_df):,} clips available across {sampled_clips_df['client_id'].nunique():,} speakers\")\n",
        "else:\n",
        "    print(sampled_clips_df.groupby(['language', 'language_name']).size().reset_index(name='count'))\n",
        "    print(f\"\\nTotal: {len(sampled_clips_df):,} clips available\")\n",
        "\n",
        "# Show shuffled clips (only columns that exist)\n",
        "print(\"\\nShuffled clips preview:\")\n",
        "display_cols = ['path', 'language', 'language_name']\n",
        "optional_cols = ['sentence', 'gender', 'age', 'duration_ms', 'client_id']\n",
        "display_cols.extend([col for col in optional_cols if col in sampled_clips_df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listen to sampled clips\n",
        "def play_sampled_clips(df: pd.DataFrame, max_per_language: int = 2):\n",
        "    \"\"\"Play sample audio clips from the dataframe.\"\"\"\n",
        "    for lang in sorted(df['language'].unique()):\n",
        "        lang_df = df[df['language'] == lang].head(max_per_language)\n",
        "        lang_name = lang_df['language_name'].iloc[0]\n",
        "        \n",
        "        display(HTML(f\"<h3>{lang_name} ({lang})</h3>\"))\n",
        "        \n",
        "        for _, row in lang_df.iterrows():\n",
        "            print(f\"File: {row['path']}\")\n",
        "            if 'sentence' in row and pd.notna(row.get('sentence')):\n",
        "                print(f\"Sentence: {row['sentence'][:100]}...\" if len(str(row['sentence'])) > 100 else f\"Sentence: {row['sentence']}\")\n",
        "            if pd.notna(row.get('gender')):\n",
        "                print(f\"Gender: {row['gender']}, Age: {row.get('age', 'N/A')}\")\n",
        "            display(Audio(row['file_path']))\n",
        "            print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the raw street name (what will be spoken)\n",
        "def extract_raw_street_name(phrase):\n",
        "    \"\"\"Extract the street name from the phrase (e.g., 'I'm on ALEMANY' -> 'ALEMANY').\"\"\"\n",
        "    return phrase.replace(\"I'm on \", \"\").strip()\n",
        "\n",
        "# Extract clean street name for filename\n",
        "def extract_filename_street_name(phrase):\n",
        "    \"\"\"Extract and clean street name for use in filename.\"\"\"\n",
        "    street = phrase.replace(\"I'm on \", \"\").strip()\n",
        "    # Replace spaces with underscores, remove apostrophes\n",
        "    street = re.sub(r\"['\\s]+\", \"_\", street)\n",
        "    # Remove any other special characters\n",
        "    street = re.sub(r\"[^a-zA-Z0-9_]\", \"\", street)\n",
        "    return street #keep it all caps\n",
        "\n",
        "# Raw street name (what TTS will speak)\n",
        "streets_df['street_name_raw'] = streets_df['name'].apply(extract_raw_street_name)\n",
        "# Clean street name for filenames\n",
        "streets_df['street_name'] = streets_df['name'].apply(extract_filename_street_name)\n",
        "\n",
        "print(streets_df[['name', 'street_name_raw', 'street_name']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Voice Clone Generation - Helper Functions\n",
        "# =============================================================================\n",
        "# CLIENT_ID_SHORT_LENGTH is defined in Configuration cell (cell 2)\n",
        "\n",
        "def get_short_client_id(client_id: str, length: int = CLIENT_ID_SHORT_LENGTH) -> str:\n",
        "    \"\"\"Get shortened client ID for use in filenames.\"\"\"\n",
        "    return client_id[:length]\n",
        "\n",
        "\n",
        "def prepare_text_for_language(street_name_raw: str, language: str) -> str:\n",
        "    \"\"\"Add language-specific prefix and suffix to text.\n",
        "    \n",
        "    Args:\n",
        "        street_name_raw: Raw street name text\n",
        "        language: Language code (e.g., 'es', 'fr', 'de')\n",
        "        \n",
        "    Returns:\n",
        "        Text with language-specific greeting prefix and suffix\n",
        "    \"\"\"\n",
        "    prefix = LANGUAGE_TO_PREFIX.get(language, \"\")\n",
        "    suffix = LANGUAGE_TO_SUFFIX.get(language, \"\")\n",
        "    return f\"{prefix}{street_name_raw}{suffix}\"\n",
        "\n",
        "\n",
        "def create_output_filename(short_id: str, street_name: str, language: str) -> str:\n",
        "    \"\"\"Create standardized output filename.\n",
        "    \n",
        "    Args:\n",
        "        short_id: Shortened client/speaker ID\n",
        "        street_name: Clean street name (safe for filenames)\n",
        "        language: Language code\n",
        "        \n",
        "    Returns:\n",
        "        Filename in format: {short_id}_{street_name}_{language}.wav\n",
        "    \"\"\"\n",
        "    return f\"{short_id}_{street_name}_{language}.wav\"\n",
        "\n",
        "\n",
        "def convert_mp3_to_wav(mp3_path: str, speaker_id: str, output_dir: str = \"temp_wav\") -> str:\n",
        "    \"\"\"Convert MP3 audio to WAV format for better XTTS compatibility.\n",
        "    \n",
        "    Args:\n",
        "        mp3_path: Path to input MP3 file\n",
        "        speaker_id: Speaker identifier for output filename\n",
        "        output_dir: Directory to save converted WAV files\n",
        "        \n",
        "    Returns:\n",
        "        Path to converted WAV file\n",
        "        \n",
        "    Raises:\n",
        "        FileNotFoundError: If mp3_path doesn't exist\n",
        "        RuntimeError: If FFmpeg conversion fails\n",
        "    \"\"\"\n",
        "    if not os.path.exists(mp3_path):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {mp3_path}\")\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    safe_speaker_id = re.sub(r'[^\\w\\-]', '_', speaker_id)\n",
        "    wav_path = os.path.join(output_dir, f\"{safe_speaker_id}.wav\")\n",
        "    \n",
        "    # Skip if already converted\n",
        "    if os.path.exists(wav_path):\n",
        "        return wav_path\n",
        "    \n",
        "    # Convert using ffmpeg (22050 Hz, mono)\n",
        "    try:\n",
        "        subprocess.run([\n",
        "            'ffmpeg', '-i', mp3_path,\n",
        "            '-ar', '22050',\n",
        "            '-ac', '1',\n",
        "            '-y',\n",
        "            wav_path\n",
        "        ], check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"FFmpeg conversion failed: {e.stderr}\")\n",
        "    \n",
        "    return wav_path\n",
        "\n",
        "\n",
        "def generate_single_clone(\n",
        "    tts,\n",
        "    text: str,\n",
        "    output_path: str,\n",
        "    ref_audio: str,\n",
        "    language: str\n",
        ") -> None:\n",
        "    \"\"\"Generate a single voice clone audio file.\n",
        "    \n",
        "    Args:\n",
        "        tts: TTS model instance\n",
        "        text: Text to synthesize\n",
        "        output_path: Where to save the output file\n",
        "        ref_audio: Path to reference audio for voice cloning\n",
        "        language: Language code for synthesis\n",
        "    \"\"\"\n",
        "    tts.tts_to_file(\n",
        "        text=text,\n",
        "        file_path=output_path,\n",
        "        speaker_wav=ref_audio,\n",
        "        language=language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_speaker_phrases(\n",
        "    tts,\n",
        "    speaker_id: str,\n",
        "    short_id: str,\n",
        "    language: str,\n",
        "    ref_audio: str,\n",
        "    phrases_df: pd.DataFrame,\n",
        "    output_dir: str,\n",
        "    pbar\n",
        ") -> tuple[list[dict], list[tuple]]:\n",
        "    \"\"\"Process all phrases for a single speaker.\n",
        "    \n",
        "    Args:\n",
        "        tts: TTS model instance\n",
        "        speaker_id: Full client ID\n",
        "        short_id: Shortened client ID\n",
        "        language: Language code\n",
        "        ref_audio: Path to reference audio\n",
        "        phrases_df: DataFrame with phrase information\n",
        "        output_dir: Output directory for generated files\n",
        "        pbar: tqdm progress bar\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (generated_files, errors) lists\n",
        "    \"\"\"\n",
        "    generated = []\n",
        "    errors = []\n",
        "    \n",
        "    for _, phrase_row in phrases_df.iterrows():\n",
        "        # Prepare text and filenames\n",
        "        street_name_raw = phrase_row['street_name_raw']\n",
        "        street_name = phrase_row['street_name']\n",
        "        text = prepare_text_for_language(street_name_raw, language)\n",
        "        \n",
        "        output_filename = create_output_filename(short_id, street_name, language)\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "        \n",
        "        # Skip if already exists\n",
        "        if os.path.exists(output_path):\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "        \n",
        "        # Update progress bar with current item\n",
        "        pbar.set_postfix_str(f\"{language}/{street_name[:15]}\")\n",
        "        \n",
        "        try:\n",
        "            generate_single_clone(tts, text, output_path, ref_audio, language)\n",
        "            generated.append({\n",
        "                'client_id': speaker_id,\n",
        "                'short_id': short_id,\n",
        "                'language': language,\n",
        "                'street_name': street_name,\n",
        "                'text_spoken': text,\n",
        "                'output_file': output_path\n",
        "            })\n",
        "        except Exception as e:\n",
        "            errors.append((speaker_id, text, str(e)))\n",
        "        \n",
        "        pbar.update(1)\n",
        "    \n",
        "    return generated, errors\n",
        "\n",
        "\n",
        "def print_generation_summary(generated_count: int, errors: list) -> None:\n",
        "    \"\"\"Print summary of generation results.\n",
        "    \n",
        "    Args:\n",
        "        generated_count: Number of successfully generated files\n",
        "        errors: List of error tuples\n",
        "    \"\"\"\n",
        "    print(f\"\\nGeneration complete!\")\n",
        "    print(f\"   Successfully generated: {generated_count:,} files\")\n",
        "    print(f\"   Errors: {len(errors)}\")\n",
        "    \n",
        "    if errors:\n",
        "        print(\"\\nErrors encountered:\")\n",
        "        for err in errors[:10]:\n",
        "            print(f\"   {err}\")\n",
        "        if len(errors) > 10:\n",
        "            print(f\"   ... and {len(errors) - 10} more errors\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Main Generation Function\n",
        "# =============================================================================\n",
        "\n",
        "def generate_voice_clones(\n",
        "    speakers_df: pd.DataFrame,\n",
        "    phrases_df: pd.DataFrame,\n",
        "    output_dir: str = \"outputs\",\n",
        "    convert_to_wav: bool = True\n",
        ") -> tuple[pd.DataFrame, list]:\n",
        "    \"\"\"Generate voice clones for each speaker saying each phrase.\n",
        "    \n",
        "    Args:\n",
        "        speakers_df: DataFrame with columns: client_id, file_path, language\n",
        "        phrases_df: DataFrame with columns: street_name_raw, street_name\n",
        "        output_dir: Directory to save output files\n",
        "        convert_to_wav: Whether to convert MP3 reference audio to WAV first\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (generated_df, errors):\n",
        "            - generated_df: DataFrame with info about generated files\n",
        "            - errors: List of error tuples (client_id, text, error_msg)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    total_generations = len(speakers_df) * len(phrases_df)\n",
        "    print(f\"Starting voice cloning generation\")\n",
        "    print(f\"   Speakers: {len(speakers_df)}\")\n",
        "    print(f\"   Phrases: {len(phrases_df)}\")\n",
        "    print(f\"   Total generations: {total_generations:,}\")\n",
        "    print(f\"   Output directory: {output_dir}/\")\n",
        "    print()\n",
        "    \n",
        "    all_generated = []\n",
        "    all_errors = []\n",
        "    \n",
        "    with tqdm(total=total_generations, desc=\"Generating audio\") as pbar:\n",
        "        for _, speaker in speakers_df.iterrows():\n",
        "            client_id = speaker['client_id']\n",
        "            short_id = get_short_client_id(client_id)\n",
        "            language = speaker['language']\n",
        "            ref_audio = speaker['file_path']\n",
        "            \n",
        "            # Convert MP3 to WAV if needed\n",
        "            if convert_to_wav and ref_audio.endswith('.mp3'):\n",
        "                try:\n",
        "                    ref_audio = convert_mp3_to_wav(ref_audio, short_id)\n",
        "                except Exception as e:\n",
        "                    all_errors.append((client_id, \"wav_conversion\", str(e)))\n",
        "                    pbar.update(len(phrases_df))\n",
        "                    continue\n",
        "            \n",
        "            # Process all phrases for this speaker\n",
        "            generated, errors = process_speaker_phrases(\n",
        "                tts=tts,\n",
        "                speaker_id=client_id,\n",
        "                short_id=short_id,\n",
        "                language=language,\n",
        "                ref_audio=ref_audio,\n",
        "                phrases_df=phrases_df,\n",
        "                output_dir=output_dir,\n",
        "                pbar=pbar\n",
        "            )\n",
        "            \n",
        "            all_generated.extend(generated)\n",
        "            all_errors.extend(errors)\n",
        "    \n",
        "    print_generation_summary(len(all_generated), all_errors)\n",
        "    \n",
        "    return pd.DataFrame(all_generated), all_errors\n",
        "\n",
        "\n",
        "print(\"Generation functions defined. Ready to run.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the voice cloning generation for all speakers and phrases\n",
        "# Generate ONE file per street, with a randomly selected speaker\n",
        "\n",
        "_rng.seed(RANDOM_SEED)\n",
        "\n",
        "output_dir = Path(PROJECT_DIR) / \"outputs\"\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "existing_files = list(output_dir.glob(\"*.wav\"))\n",
        "print(f\"Output directory: {output_dir}/\")\n",
        "print(f\"   Existing files: {len(existing_files)}\")\n",
        "print(f\"   Streets to generate: {len(streets_df)}\")\n",
        "\n",
        "# For each street, randomly assign one speaker from sampled_clips_df\n",
        "speaker_assignments = [sampled_clips_df.sample(n=1, random_state=_rng.randint(0, 2**31)).iloc[0] \n",
        "                       for _ in range(len(streets_df))]\n",
        "\n",
        "all_generated = []\n",
        "all_errors = []\n",
        "\n",
        "with tqdm(total=len(streets_df), desc=\"Generating audio\") as pbar:\n",
        "    for i, (_, street_row) in enumerate(streets_df.iterrows()):\n",
        "        speaker = speaker_assignments[i]\n",
        "        client_id = speaker['client_id']\n",
        "        short_id = get_short_client_id(client_id)\n",
        "        language = speaker['language']\n",
        "        ref_audio = speaker['file_path']\n",
        "        \n",
        "        street_name = street_row['street_name']\n",
        "        street_name_raw = street_row['street_name_raw']\n",
        "        text = prepare_text_for_language(street_name_raw, language)\n",
        "        \n",
        "        # Build output filename: {short_id}_{street_name}_{language}.wav\n",
        "        out_filename = create_output_filename(short_id, street_name, language)\n",
        "        out_path = os.path.join(str(output_dir), out_filename)\n",
        "        \n",
        "        # Skip if already exists\n",
        "        if os.path.exists(out_path):\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "        \n",
        "        # Convert MP3 to WAV if needed\n",
        "        if ref_audio.endswith('.mp3'):\n",
        "            try:\n",
        "                ref_audio = convert_mp3_to_wav(ref_audio, short_id)\n",
        "            except Exception as e:\n",
        "                all_errors.append((client_id, text, str(e)))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "        \n",
        "        try:\n",
        "            generate_single_clone(tts, text, out_path, ref_audio, language)\n",
        "            all_generated.append({\n",
        "                'client_id': client_id,\n",
        "                'short_id': short_id,\n",
        "                'language': language,\n",
        "                'text': text,\n",
        "                'street_name': street_name,\n",
        "                'file_path': out_path\n",
        "            })\n",
        "        except Exception as e:\n",
        "            all_errors.append((client_id, text, str(e)))\n",
        "        \n",
        "        pbar.update(1)\n",
        "\n",
        "print(f\"\\nDone! Generated {len(all_generated)} files, {len(all_errors)} errors\")\n",
        "\n",
        "# Save the generation log\n",
        "generated_df = pd.DataFrame(all_generated)\n",
        "log_path = output_dir / \"generation_log.csv\"\n",
        "generated_df.to_csv(log_path, index=False)\n",
        "print(f\"Generation log saved to {log_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
